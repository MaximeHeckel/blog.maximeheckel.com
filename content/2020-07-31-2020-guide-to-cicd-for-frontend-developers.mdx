---
title: 'The 2020s guide to CI/CD for frontend developers'
subtitle: How to ship your app faster, more reliably and make your team unstoppable with automation.
date: '2020-07-31T08:00:00.000Z'
categories: []
keywords: ['tests', 'release', 'production', 'development', 'continuous integration continuous delivery', 'end-to-end testing', 'e2e', 'unit-testing', 'integration-testing', 'branch preview', 'feature flags', 'accessibility', 'pipeline']
slug: 2020-guide-to-cicd-for-frontend-developers
featured: true
colorFeatured: 'linear-gradient(160deg,rgb(74, 123, 210) 0%,rgba(28,90,221,0.55) 69%)'
fontFeatured: '#FFFFFF'
---

If you've been following my work for a while, or read my previous articles, you might have noticed that I love building tools that improve the reliability and the scalability of the projects I work on, and  **C**ontinuous **I**ntegration and **C**ontinuous **D**elivery pipeline, also referred to as **CI/CD**, is one of them.
Building such a pipeline and making it as automated as possible, is like giving superpowers to your team. With it, you can enable your organization to deliver:

- Code that respects consistent styling guidelines and formatting
- Reliable software is tested and so are its subsequent releases to avoid regressions
- Consistent releases: releasing a new version to the customer is as easy as possible and your team can ship fixes to production in no time
- Features that can easily be reverted if they degrade the user experience
- Any upcoming change to the product can be previewed as an independent unit of change
- Use every developer's time as efficiently as possible. Developer's cost money and you don't want them to be constantly putting out fires in production.  Automate testing and releases, remove all the humans in the process as much as possible. More testing means fewer bugs means less fear of change. Less fear of change means more experimentation and innovation. More automation means more time for experimentation and innovation.

> Change must be in the DNA of the team -- [Eric Elliott in How to Build a High-Velocity Development Team](https://medium.com/javascript-scene/how-to-build-a-high-velocity-development-team-4b2360d34021)

If your team suffers from complex release processes, struggles to patch production within the same day or to get a new feature to the customers reliably: **this article is for you!**
In this post, I'll give you all the tools that you and your team need to build a high-velocity development environment, eradicate the fear of releasing, and establishing processes **for your team to become unstoppable**.  Like the title suggests, the following will be written for frontend developers since this is the area where I'm the most knowledgeable, especially when it comes to tooling. However, the concepts and steps that I will detail can also be valuable to backend developers who are looking to improve their team's testing and release pipeline.

## The impact of automation on your team, your org ,and your users

When starting to work on a new CI/CD pipeline, or looking at improving an existing one, it's essential to target the efforts where you want to make the most positive impact:

- **unit-testing, formatting, linting, and integration-testing**: impact mainly the developer within your team. Having a good habit of writing unit tests, and having consistent code styling can increase velocity within the team. These are what I called fast to run fast to fail: they can be run quickly to identify any issues withing the codebase and act as the first safeguard against bugs.
- **end to end testing, automated release, and branch previews** are more impactful at the cross-functional or organizational level. **End to End testing** will, for example, enable **your frontend team and backend team** to test some critical user paths. **The automated releases** ensure things are released with as little friction as possible and that your entire org can address a customer request as fast as possible. Finally, **branch previews** enable **your frontend team and QA team** to review, work before it lands on production. Each upcoming feature or fix can be hosted in its service and tested on its own.
- **feature flags and accessibility testing** are more customer-facing. They guarantee a better and more inclusive experience for all your users and also avoid any service disruption when it comes to releasing new features.

The following showcases what is a rather complete CI/CD pipeline is composed of and which of your team, organization, customers are impacted the most by each step of that said pipeline:


TEAM.           |.        ORG.         |         USER

--------------------------------------------------> 
(TO DO: CHART)

## Linting, Formatting, and Unit tests

These four items of the CI/CD pipeline listed above are the fundamental pieces for your team to ship more reliable software, faster.

### Linting and formatting

**[ANIMATION LINTING]**

**Linting and formatting** are essential to keep your codebase **consistent** and **clean**. Each team member should follow the same rules and conventions when it comes to writing code. **Consistency** in the codebase itself is essential: 

-   you do not want to bring confusion on how to write a given piece of your app when you onboard a new team members
-   you do not want to have to document multiple ways of doing the same thing

[Card For tools]

For this step, I want my tools to be fast and reliable. It should only take **a few seconds **to lint and format my codebase. As a frontend engineer, I use

-   **[ESlint](https://eslint.org/)** for linting, it comes with a set of rules to write proper Javascript, and these rules can be customized to your own team's fit. Additionally, should you need something more specific, you can build your own ESLint rules, [I wrote about it here](https://blog.maximeheckel.com/posts/how-to-build-first-eslint-rule), it's an interesting exercise that involves Abstract Syntax Tree (AST).
-   **[Prettier](https://prettier.io/)** for formatting. It became de defacto formatting tool for Javascript developers within a few years. I set it up in my project and editor in a way that saving a file will format it automatically for me.

As said above, this step must be super fast. So fast that you can execute this step as a [pre-commit hook](https://githooks.com/) (an arbitrary script that runs on every commit. I like using **[husky](https://www.npmjs.com/package/husky)** to set these up) as it will ensure that the code is formatted and readable **before** it's up for review by your teammates.

Then, we arrive at the first set of tests that will be executed in our CI/CD pipeline: **Unit tests**.

### Unit tests

**[ANIMATION UNIT TESTS]**

As stated earlier, I like to call these tests **fast to run**, **fast to fail. **They should not take an extensive amount of time to run and should reveal errors or bugs in a matter of a few seconds or even a few minutes depending on the scale of your project.

The aim here is to test each part of your app as "units" or isolated components. In a React project, for example, these tests can cover: 

-   **Components**: I like to use unit tests to ensure my components have the proper behavior and are functioning as expected **on their own**, i.e.** not in conjunction with other components or views of my app**. 
-   **Reducers / State / Actions**: unit tests can help to validate that your state is updated in a specific way for a given action. Reducers are pure function (i.e. functions that always return the same output for a given input)
-   **Utility functions**: we build a lot of helpers, or abstract a lot of functions in our projects: these are a perfect example of things that you might want to write unit tests for.

I like unit tests a lot because they act as a sanity check for your project to make sure its pieces work as intended **over time**, in a very efficient way (fast, reliable).

[Card For tools]

As frontend developers, you might have probably heard about **[Jest](https://jestjs.io/)**. It's the most popular Javascript testing framework and has been for a few years now. Jest is the testing tool I always install first in my Javascript projects. To run tests on my React apps, for example, I use it in combination with:

- **[@testing-library/react](https://testing-library.com/docs/react-testing-library/intro)** : If you want to write maintainable tests over time without worrying about implementation details. I mainly use it to render individual components and test them.
- **[@testing-library/hooks](https://github.com/testing-library/react-hooks-testing-library)**: This library gives you all the tooling necessary to test your custom hooks.
- **[@testing-library/jest-dom](https://testing-library.com/docs/ecosystem-jest-dom)**: This package gives you extra DOM element matchers to make your test even easier to write and read.

The @testing-library maintainers also provided a ton of other packages that will help you test your app no matter the framework (Svelte, VueJS, etc).

Below, you will find code snippets showcasing components, reducers, or simply functions tested with Jest. These are meant to illustrate how I usually write tests in different situations. As I'm not very literate in other libraries and frameworks than React, I'm sadly not going to focus much on these in the following examples, however, the concepts and techniques should remain similar regardless of what you're using to build your apps.

[CODE SNIPPETS]

<Callout variant="danger">

**A note about test coverage**

I see a lot of people putting quarterly objectives for test coverage. Test coverage should **not** be an objective as a team. It is a metric to measure whether your team is making progress when it comes to testing your consumer app.

However, if your project is let's say an open-source library or a design system containing components that are used across your entire organization, I'd advocate for focusing on guaranteeing a high test coverage. If what you're building is a more complex app involving several views, side effects, high test coverage scores are less relevant.

</Callout>

<Callout variant="info">

**A note on type checking**

I'm skipping type checking in this section on purpose as this step deserves an article on its own.

</Callout>

Putting the steps highlighted in this part together gives a good foundation for a team to release a project with a bit more confidence and a consistent codebase.

## Integration and end-to-end testing

I'm dedicating this section to both integration and end-to-end testing as I sometimes see these two types of testing used interchangeably and I think that it's important to know the nuance.

### Integration tests

This is perhaps where most of your effort should go when writing tests.

Why? Well, **when considering the effort it takes to write tests, the time it takes to execute them and the confidence level it gives back to your team: integration tests are simply the bests**. Unit tests give you a low confidence level but are fast to run, while end-to-end tests are slow to execute (sometimes taking over an hour in some large apps) and require expensive infrastructure to run but give you the highest confidence level possible.

> Write tests not too much mostly integrations -- [Guillermo Rauch](https://twitter.com/rauchg)

If you want to know why in detail, I advise reading [Kent C Dodd's *Write Tests* blog post](https://kentcdodds.com/blog/write-tests).

While unit tests aimed to test parts of your project in isolation, integration tests, aim to test whether an entire set of units work together as expected. They also allow you to test full user flows and all the different paths they can take (error state, loading state, success state).

With integration tests, I like testing groups of components, functionalities together such as:

-   **Navigation**: Does clicking on the user setting menu item loads the expected view?
-   **Forms**: Fill up the form in all possible ways (valid and invalid, with and without optional fields). Test that the expected error messages are displayed when invalid. Validate that clicking on submit sends the right payload when valid. A form like this may be composed of components, reducers, and utility functions that we tested individually in the unit test phase. Here we're testing them working altogether in a specific context.
-   **Views **depending on external data: Test your list view that's fetching some data with different mocked API responses: does it show the proper empty state if there's no data? Is the filter button enabled if your API returned an error? Does it show a notification if the fetch was successful? 

I could go on and on with different examples but this is what I usually focus on validating when writing integration tests. I try to validate all the possible paths that a group of components, a form, or a view can take.

[Card tools]:

When it comes to integration tests I'm split between using two different tools, sometimes within the same project. 

-   **Jest**: You can write pretty advanced integration tests with Jest, `@testing-library/react`, and all the cool tools we've mentioned before. I recently started using [msw](https://github.com/mswjs/msw) to mock the APIs that the views I'm testing are depending on different status codes or payload. If like me, you struggled to mock APIs, this library is for you!
-   **[Cypress](https://www.cypress.io/)**: It comes with a neat way to [write fixtures and mock API endpoints](https://docs.cypress.io/api/commands/fixture.html) and thus run some integration tests. I mainly use it to validate some browser-related behaviors like: are the proper query parameters passed to the URL? Can I load a view in a specific state by adding this set of parameters to the URL?

[CODE SNIPPET example of jest integration test with msw]

## End to End testing

End-to-End tests, or also sometimes called e2e, are the set of tests that are the closest to what the user should experience when using your product. In most frameworks like Selenium or Cypress, an e2e test suite is nothing more than a **scripted user flow** that the computer will go through. Additionally, most of these tests will be executed **directly within a browser **which gives you the ability to validate whether your app runs properly on different browsers that your customer may use.

<Callout variant="info">

If you're curious about cross-browser testing, [I wrote a blog post about it earlier this year](https://blog.maximeheckel.com/posts/running-cross-browser-cypress-github-ci) showcasing a very simple setup!

</Callout>

End to End tests have multiple pros and cons

**Pros:**

- They are the most realistic set of tests: you run your tests against the built version of your frontend app.
- They validate whether your **entire product** works as expected, that includes the backend, APIs, the databases that might be involved, etc.

**Cons:**

-   They are slow, complex, and expensive to run. As of today, e2e steps are the longest steps in most of my CI/CD pipelines. Additionally, they are very hard to maintain over time as your app becomes more complex, tests might become *flaky*, you might have to rewrite them completely to adapt to some new UX elements.
-   You only test what I call the "Happy Path". For example, when running an e2e test against a form that sends data to an API, you can only test whether the case where things go as expected as this test depends on external APIs, backend services that here are not mocked and are supposed to work.

[IMAGE HAPPY PATHS TESTING VS ALL PATHS (INTEGRATION) TESTING]

[Card tools]:

If you haven't introduced e2e tests in your team just yet, I'd highly recommend **[Cypress](https://www.cypress.io/) ** as a starting point. The Cypress team has built the most accessible way to write e2e tests to my eyes and also has the best documentation and community support.

Rather than showcasing some code snippets, I'd like to share with you some of my tips that I keep using for writing e2e tests:

- Each test should be **self-contained**. For a given suite with a test A, B, and C, the whole suite fails because test A failed might make it hard to find other issues with test B and C. I try to keep each test as independent as possible as it saves me time and effort when debugging a broken test.
- Trigger API calls before the test to create all the objects you need for your test. For a given object in your app, you might have a "create", "read", and "update" flow and I want to test all three of them. However, the "read" and "update" flow can't be self-contained if they depend on the "create" flow being successful. Thus I tend to create custom commands to call the related APIs to create the objects I need before executing a test.
- Promote good test practices within your team, run them often (we'll get to that in the next part), fix them as soon as they break, gather a list of tests that you want to write, and prioritize them.
- If you currently have 0 e2e tests in your codebase and don't know which test to write first: **start by writing a test that validates the most buggy or flaky feature of your app**. As stated earlier in this post, emphasize the impact of your CI/CD and tests by making the product better than it was before you wrote the test. Your organization and customers will be more than thankful.

## Accessibility audit and testing

This is the last and the most important piece of the CI/CD pipeline. Often enough it's also the most complicated because guaranteeing for your frontend project to be 100% accessible is no easy feat, but it's something **that everyone should strive for**.

Nothing is more efficient than sitting in front of your computer and using your app with a screen reader, however, here are some tools that I use to **guide the accessibility efforts:**

-   [Lighthouse CI](https://github.com/GoogleChrome/lighthouse-ci): This is a suite of tools to help you audit performance, accessibility, and whether your app follows best practices. I use this tool to essentially **hold the line and ensure things do not get worse over time**. It allows you to put together "performance and accessibility budgets" and thresholds and will fail in case your score goes below the targetted budget. This probably deserves an entire article on its own.
-   [Cypress Axe](https://github.com/avanslaars/cypress-axe): This package works on top of Cypress and allows you to run accessibility focus test suite. It helped me find some more complex accessibility issues that Lighthouse CI would skip. I wrote a blog post about Cypress Axe last year (<https://blog.maximeheckel.com/posts/automated-ui-accessibility-testing-with-cypress-cc2e38231241>), and invite you to check it out if you want to learn more about it!

<Callout variant="info">

I also use a couple of chrome extensions to track and find new accessibility issues:

-   [Accessibility Insight](https://accessibilityinsights.io/)
-   [Chrome Lens](https://chrome.google.com/webstore/detail/chromelens/idikgljglpfilbhaboonnpnnincjhjkd)

These, however, are purely used outside of my CI/CD pipeline, but I figured they were perhaps worth mentioning.

</Callout>

## Automation: When and how to run my tests and release

Now that we have written some unit, integration, and e2e tests, it's time to talk automation. The objective for your team should be to automate as much as possible, from running the tests to previewing the deployments, to deploying to production. **The only manual step left in your CI/CD pipeline should be the code review. **Automation is the key component of any High-Velocity development team.

**Validate every code change**

As of now, we know how to run these tests locally but we want to ensure that these tests can be run automatically every time a change occurs on the codebase. 

I generally am in favor of running these tests on **every pull request**. **Each change has to be tested before it's merged to the main branch without any exception**. That is the secret to keep your project stable and bug-free: tests are run as often as possible, for every unit of change. Tests must pass for any code change to reach the main branch.

Here are a couple of sample Github Actions workflows that I use on several projects. If you do not have an automated CI/CD pipeline already in place you can use those to get started quickly, it integrates very well with Github PRs and is very easy to iterate over:

[GH ACTION SNIPPETS]

Another thing I tend to run on every PR is **preview deployments.** These are perhaps my favorite feature of the whole CI/CD pipeline: you get a standalone deployment each PR that is accessible through a unique endpoint. Each deployment is a version of your frontend project with a specific change. This can not only help your team to speed up reviews, but it also lets your design and product team validate some new features easily. **They shouldn't have to run your project on their computers to preview some changes: the review process should be as fast as possible and without roadblocks.**

<Callout variant="info">

There are a couple of services out there that provide a great preview deployment feature like Netlify (<https://www.netlify.com/>) and Vercel ([https://vercel.com/](https://vercel.com)). If your org is using some other services to deploy and host your project, you can easily integrate with those just to use the preview deployment feature, or you can even implement your own! I plan on publishing a blog post about how I built such a service with Google Cloud for my team.

</Callout>

**Releases**

The last thing we want to automate is **the release process**. You do not want to have to run 20 scripts, manually, in a specific order, to get your application from your main branch to production. For this, I tend to favor having what I call a **release branch in my Github repository** and have the automated scripts run **every time the main branch is merged on the release branch**. You could also run the automated script on other events such as when you **tag a release or have scheduled deployments**. At this point, it depends on your team and how you want to do your release.

Here's a sample GitHub Action that runs a script (here fake) following a push event on a release branch:

[GH ACTION SNIPPETS]

Another essential point regarding releases is that, once you automate them, you should do releases as often as possible. By increasing the cadence of production deployments you limit the scope of each deployment. This in return limits the number of issues that could impact your user. On top of that, you can add **Feature Flags, **to allow **a slow rollout **of a big new feature. This also helps you mitigate any potential problems that a massive change could create once deployed to production and also gives you even more control over the release of a new feature. I also like feature flags because they also provide a better experience for the end-user, the rollouts are smoother and can be more targetted: **you may only want to enable a given feature to a subset of user before making it generally available.**

## Conclusion

This article contains all the concepts, tools, and knowledge I use daily to ship software without sweating. I know that it is pretty dense and that there's a lot to take in, but really if you implement each of these steps and concepts in your project I can ensure you that this will enable you, your team and your organization to do **the best work you've ever done**. 

Below you'll find a couple of extra links that I found useful when learning about tests and CI/CD. Some of them are blog posts, some of them are classes, I found them all very valuable and I'm sure they would help you in your journey to build a high-velocity development environment and make you and your team unstoppable.

**Resources:**

- [Testing Javascript](https://testingjavascript.com/)
- [Write tests. Not too many. Mostly integration](https://kentcdodds.com/blog/write-tests)
- [Automating safe, hands-off deployments](https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/)
- [Deploy, Preview, Test](https://rauchg.com/2020/develop-preview-test)
- [Types or Tests: Why Not Both?](https://css-tricks.com/types-or-tests-why-not-both/)
- [How To Build a High-Velocity Development team](https://medium.com/javascript-scene/how-to-build-a-high-velocity-development-team-4b2360d34021)
- [Git Hooks](https://githooks.com/)
- [Github Actions Documentation](https://docs.github.com/en/actions)
- [The Testing Trophy](https://twitter.com/kentcdodds/status/960723172591992832)